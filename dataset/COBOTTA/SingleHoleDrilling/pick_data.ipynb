{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522017a5-4177-4a05-9234-22e861445202",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(os.path.join(Path().resolve(), '../../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a3738a-7e76-4797-a028-51a66ee3cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4316e774-5ee6-4d3e-945d-57b456ed6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0500fe6a-6097-4487-ad6f-38b0f149d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2022.8.12-py3-none-any.whl (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.5/208.5 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/docker/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/docker/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from scikit-image) (1.9.1)\n",
      "Collecting networkx>=2.2\n",
      "  Downloading networkx-2.8.7-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /home/docker/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from scikit-image) (2.21.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/docker/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/docker/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/docker/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from scikit-image) (1.23.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/docker/.pyenv/versions/3.8.0/lib/python3.8/site-packages (from packaging>=20.0->scikit-image) (2.4.7)\n",
      "Installing collected packages: tifffile, networkx, scikit-image\n",
      "Successfully installed networkx-2.8.7 scikit-image-0.19.3 tifffile-2022.8.12\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f464fc-43d4-4712-8280-570b56ce41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import img_as_float, img_as_ubyte\n",
    "\n",
    "switch1 = 0\n",
    "n_blur1 = 2\n",
    "ksize1 = 5\n",
    "th_size = 5\n",
    "switch2 = 3\n",
    "n_blur2 = 1\n",
    "ksize2 = 5\n",
    "\n",
    "blurs = [\"blur\", \"GaussianBlur\", \"bilateralFilter\", \"medianBlur\"]\n",
    "def make_binary_image(img, switch1, n_blur1, ksize1, size, switch2, n_blur2, ksize2):\n",
    "    _img_col = copy.deepcopy(img).astype(np.float32)\n",
    "    \n",
    "    method1 = blurs[switch1]\n",
    "    for k in range(n_blur1):\n",
    "        if method1 == \"blur\":\n",
    "            _img_col = cv2.blur(_img_col, (ksize1,ksize1))\n",
    "        elif method1 == \"medianBlur\":\n",
    "            if ksize1 > 5:\n",
    "                ksize1 = 5\n",
    "            _img_col = cv2.medianBlur(src=_img_col, ksize=ksize1)\n",
    "        elif method1 == \"GaussianBlur\":\n",
    "            _img_col = cv2.GaussianBlur(_img_col, (ksize1,ksize1), sigmaX=3)\n",
    "        elif method1 == \"bilateralFilter\":\n",
    "            _img_col = cv2.bilateralFilter(src=_img_col, d=ksize1, sigmaColor=75, sigmaSpace=75)\n",
    "        else:\n",
    "            method1 = \"None\"\n",
    "\n",
    "    _img_col = img_as_float(_img_col)\n",
    "    _img_gray = rgb2gray(_img_col).astype(np.uint8)\n",
    "        \n",
    "    img_adap = cv2.adaptiveThreshold(_img_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, size, 1)\n",
    "    \n",
    "    method2 = blurs[switch2]\n",
    "    _img_bin = copy.deepcopy(img_adap).astype(np.float32)\n",
    "    for k in (range(n_blur2)):\n",
    "        if method2 == \"blur\":\n",
    "            _img_bin = cv2.blur(_img_bin, (ksize2,ksize2))\n",
    "        elif method2 == \"medianBlur\":\n",
    "            if ksize2 > 5:\n",
    "                ksize2 = 5\n",
    "            _img_bin = cv2.medianBlur(src=_img_bin, ksize=ksize2)\n",
    "        elif method2 == \"GaussianBlur\":\n",
    "            _img_bin = cv2.GaussianBlur(_img_bin, (ksize2,ksize2), sigmaX=3)\n",
    "        elif method2 == \"bilateralFilter\":\n",
    "            _img_bin = cv2.bilateralFilter(src=_img_bin, d=ksize2, sigmaColor=75, sigmaSpace=75)\n",
    "        else:\n",
    "            method2 = \"None\"\n",
    "    return np.max(_img_bin)-_img_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "737bc905-f059-4e52-8bf4-1f81f97f80e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docker/.pyenv/versions/3.8.0/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset.COBOTTA.pose_processing import preprocess_pose\n",
    "\n",
    "def preprocess_data(file_name_input, folder_name_save, flag_bin=False):\n",
    "    \n",
    "    # file_name = \"{}/{}\".format(folder_name, name.replace('.bag', '.npy'))\n",
    "    print(file_name_input)\n",
    "    data = np.load(file_name_input, allow_pickle=True).item()\n",
    "    d_pose_quat = np.zeros_like(data[\"pose_quat\"])\n",
    "    d_pose_quat[1:] = data[\"pose_quat\"][1:] - data[\"pose_quat\"][:-1]\n",
    "    norm = np.linalg.norm(d_pose_quat[:,:],axis=1)\n",
    "    \n",
    "    # idx_use = np.where(norm>1e-4)[0]\n",
    "    idx_use = np.where(norm>-1)[0]\n",
    "        \n",
    "    output = dict()\n",
    "    for key in data.keys():\n",
    "        if (\"high_resolution\" in key):\n",
    "            print(key)\n",
    "            ims = data[key][idx_use]\n",
    "            ims_128 = []\n",
    "            ims_64 = []\n",
    "            size = ims.shape[1:3]\n",
    "\n",
    "            n_data = len(ims)\n",
    "            for t in range(n_data):\n",
    "                im_128 = cv2.resize(ims[t], (int(size[0]/2), int(size[1]/2)), interpolation=cv2.INTER_LINEAR)\n",
    "                ims_128.append(im_128)\n",
    "\n",
    "                im_64 = cv2.resize(ims[t], (int(size[0]/4), int(size[1]/4)), interpolation=cv2.INTER_LINEAR)\n",
    "                ims_64.append(im_64)\n",
    "\n",
    "            output[key.replace(\"_high_resolution\", \"_256\")] = ims\n",
    "            output[key.replace(\"_high_resolution\", \"_128\")] = np.array(ims_128)\n",
    "            output[key.replace(\"_high_resolution\", \"_64\")] = np.array(ims_64)\n",
    "\n",
    "        else:\n",
    "            output[key] = data[key][idx_use]\n",
    "    \n",
    "    if flag_bin:\n",
    "        output_bin = dict()\n",
    "        for key in output.keys():\n",
    "            if \"image\" in key:\n",
    "                ims = output[key]\n",
    "                ims_bin = []\n",
    "                for t in range(len(ims)):\n",
    "                    im_bin = make_binary_image(ims[t], switch1, n_blur1, ksize1, th_size, switch2, n_blur2, ksize2)\n",
    "                    im_bin = (np.array(im_bin)/255).astype(np.uint8)\n",
    "                    ims_bin.append(im_bin)\n",
    "                output_bin[key+\"_bin\"] = np.expand_dims(np.array(ims_bin), axis=-1)\n",
    "        for key in output_bin.keys():\n",
    "            output[key] = output_bin[key]\n",
    "\n",
    "    output[\"done\"][-1] = 1\n",
    "    if \"weight_value\" in output.keys():\n",
    "        output[\"weight_value_norm\"] = output[\"weight_value\"]/2000\n",
    "    \n",
    "    output = preprocess_pose(output)\n",
    "    \n",
    "    basename = os.path.basename(file_name_input)\n",
    "    save_file_name = \"{}/{}\".format(folder_name_save, basename)\n",
    "    os.makedirs(os.path.dirname(save_file_name), exist_ok=True)\n",
    "    np.save(save_file_name, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cddf5d1-d43c-4d9f-9dff-c678cd91a87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2acb321-4322-462d-a5b5-09936431692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 20 npy files!\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"cobotta_2022-05-29_point_drilling_npy_norm/train\"\n",
    "# folder_name = \"dataset/20052022_drilling_npy/validation_episodes\"\n",
    "\n",
    "# file_names = glob.glob(os.path.join(folder_name, '*/*.npy'))\n",
    "file_names = glob.glob(os.path.join(folder_name, '*.npy'))\n",
    "n_episode = len(file_names)\n",
    "\n",
    "print(\"find %d npy files!\" % n_episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d506fa-ca8c-4f6a-a720-dab4fc42871e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92e3bf51-2f6b-4ad5-b154-998b46a4eb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cobotta_2022-05-29_point_drilling_npy_norm/train'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb5201e4-62ed-483f-b01c-82d548227ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = glob.glob(os.path.join(folder_name, '*.npy'))\n",
    "# file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e453453-3957-4a04-a10a-1822b7f735dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43eb19c7-e3b6-4f16-8e44-c9d8742e2e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████████████████████▋                                                                                                                                                       | 3/20 [00:00<00:00, 28.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-52-36.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-34-24.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-36-45.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-50-03.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-32-07.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-09-11-09.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-24-02.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 13/20 [00:00<00:00, 40.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-56-49.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-26-46.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-54-48.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-42-20.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-59-26.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-09-16-08.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-09-01-21.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-29-43.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-09-04-56.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 38.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-09-13-44.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-09-08-37.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-47-01.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/train/cobotta_2022-05-29-08-39-28.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_name_save = \"dataset/train\"\n",
    "\n",
    "for file_name in tqdm(file_names):\n",
    "    preprocess_data(file_name, folder_name_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce544f31-7e51-4507-93b7-7bfb3015558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_name_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88f6464b-adf2-4531-b761-8e42f0509ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = glob.glob(os.path.join(folder_name_save, '*.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b2599-3d37-44a6-946b-ac69aed97dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47785836-ced6-423a-8f44-bc94a7d65996",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57dc9fdf-0eb7-44d7-bbd2-6ea082e0efb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find 3 npy files!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folder_name = \"cobotta_2022-05-29_point_drilling_npy_norm/validation\"\n",
    "\n",
    "# file_names = glob.glob(os.path.join(folder_name, '*/*.npy'))\n",
    "file_names = glob.glob(os.path.join(folder_name, '*.npy'))\n",
    "n_episode = len(file_names)\n",
    "\n",
    "print(\"find %d npy files!\" % n_episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b59d1d0d-0707-4e24-86f2-89a5d22c4918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 36.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cobotta_2022-05-29_point_drilling_npy_norm/validation/cobotta_2022-05-29-09-20-03.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/validation/cobotta_2022-05-29-09-21-55.npy\n",
      "cobotta_2022-05-29_point_drilling_npy_norm/validation/cobotta_2022-05-29-09-18-10.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_name_save = \"dataset/validation\"\n",
    "\n",
    "for file_name in tqdm(file_names):\n",
    "    preprocess_data(file_name, folder_name_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2bc71-8638-42c5-aea8-b7b8ad5ccfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da918c24-d3d5-4734-a577-6e4ec3101b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = glob.glob(os.path.join(folder_name_save, '*.npy'))\n",
    "# file_names = glob.glob(os.path.join(folder_name, '*.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08d3e4d7-4562-49a3-a608-d9512ac1da86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 139.07it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for file_name in tqdm(file_names):\n",
    "    # print(file_name)\n",
    "    data = np.load(file_name, allow_pickle=True).item()\n",
    "    dataset.append(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c3751-df34-4f8b-9c75-a178fbf60d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794d068-9e35-4c57-84e4-50fdd3e25a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bedc7a-f20d-42fe-a171-668e085d28f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714e084-6e0a-4ecd-a2ea-857be129b4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9150f7-28c8-4ad4-a12d-8e071a9ab7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
