# model:
observation_names_enc: ["image_84"]
observation_names_rec: ["image_84"]
condition_names: ["action"]
predict_reward: True
expert_dist:

multimodal: False
multimodal_params: # if multimodal is True, multimodal_params are used
  fusion_method:  # NN, PoE, MoPoE
  expert_dist: 
  use_prior_expert: 

activation_function:
  cnn: relu
  dense: elu
  fusion: relu

embedding_size:
  fusion: 1024
  image: 1024
  sound: 256
  other: 128

hidden_size: 200
belief_size: 200
state_size: 30
# normalization: BatchNorm # BatchNorm, InstanceNorm, GroupNorm, None
normalization: # BatchNorm, InstanceNorm, GroupNorm, None

worldmodel_LogProbLoss: False
overshooting_distance: 50
overshooting_kl_beta: 0
overshooting_reward_scale: 0
global_kl_beta: 0
free_nats: 3

kl_beta: 1
kl_balancing_alpha: 0.5
# kl_loss =    alpha    * compute_kl(stop_grad(approx_posterior), prior)
#         + (1 - alpha) * compute_kl(approx_posterior, stop_grad(prior))

model_learning_rate: 1e-3
actor_learning_rate: 8e-5
value_learning_rate: 8e-5
learning_rate_schedule: 0
adam_epsilon: 1e-7
# Note that original has a linear learning rate decay, but it seems unlikely that this makes a significant difference
grad_clip_norm: 100.0
planning_horizon: 15
discount: 0.99
disclam: 0.95